{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg97v58tCNUWTdv0fSHwxj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khatgarhaastha/KMeans/blob/main/kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ARYCfCnHRSO5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to read the data from Train, Valid and test csv files and\n",
        "# returning a list containing labels and grayscale values for digits\n",
        "\n",
        "def read_data(file_name):\n",
        "\n",
        "    data_set = []\n",
        "    with open(file_name,'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.replace('\\n','')\n",
        "            tokens = line.split(',')\n",
        "            label = tokens[0]\n",
        "            attribs = []\n",
        "            for i in range(784):\n",
        "                attribs.append(tokens[i+1])\n",
        "            data_set.append([label,attribs])\n",
        "    return(data_set)"
      ],
      "metadata": {
        "id": "AmR0Jjgp6JGg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Illustration of Return Value:**\n",
        "\n",
        "***If the input file (file_name) contains:***\n",
        "\n",
        "L1,1,2,3,...,784th_value\n",
        "\n",
        "L2,1,2,3,...,784th_value\n",
        "\n",
        "...\n",
        "\n",
        "***The returned data_set would be:***\n",
        "\n",
        "[\n",
        "   \n",
        "    [\"L1\", [\"1\", \"2\", \"3\", ..., \"784th_value\"]],\n",
        "    [\"L2\", [\"1\", \"2\", \"3\", ..., \"784th_value\"]],\n",
        "    ...\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "Zz86bKg0MPDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** All values, including the label and attributes, are read as strings since we are directly reading from a text file. If we need the attributes as integers or other types, additional type conversion would be necessary."
      ],
      "metadata": {
        "id": "PxX-cIb-OvmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the data using 'read_data' method\n",
        "\n",
        "train_data = read_data(\"train.csv\")\n",
        "valid_data = read_data(\"valid.csv\")\n",
        "test_data = read_data(\"valid.csv\")"
      ],
      "metadata": {
        "id": "1sVCR5iv5Agr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into \"labels\" and \"features\"\n",
        "\n",
        "def split_data(data):\n",
        "    labels = []\n",
        "    features = []\n",
        "    for item in data:\n",
        "        labels.append(item[0])\n",
        "        features.append(item[1])\n",
        "    return labels, features\n",
        "\n",
        "y_train, X_train = split_data(train_data)\n",
        "y_valid, X_valid = split_data(valid_data)\n",
        "y_test, X_test = split_data(test_data)\n"
      ],
      "metadata": {
        "id": "aIxjGqnSPYWc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Illustrating the labels and features of valid dataset\n",
        "#print(y_valid)\n",
        "#for i in range(len(X_valid)):\n",
        "#  print(X_valid[i])\n"
      ],
      "metadata": {
        "id": "Yjce8QgsP8YP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert the features and labels into numpy arrays and change their data type**\n",
        "\n",
        "The features are currently in the form of strings. We need to convert them to floating point values. Similarly, labels should be converted to integers."
      ],
      "metadata": {
        "id": "X7dAMI2XRCub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train, dtype=np.float32)\n",
        "y_train = np.array(y_train, dtype=np.int32)\n",
        "X_valid = np.array(X_valid, dtype=np.float32)\n",
        "y_valid = np.array(y_valid, dtype=np.int32)\n",
        "X_test = np.array(X_test, dtype=np.float32)\n",
        "y_test = np.array(y_test, dtype=np.int32)\n"
      ],
      "metadata": {
        "id": "lDHExaMbQ_Kr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This conversion is beneficial, especially when working with machine learning or other scientific computing tasks in Python. By ensuring data is in the correct format and type, operations can be performed more efficiently, and many libraries (like scikit-learn, TensorFlow, etc.) expect or perform better with NumPy arrays compared to standard Python lists."
      ],
      "metadata": {
        "id": "MqbJ3DWzR8EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalize the features**\n",
        "\n",
        "Here we'll use a simple normalization technique by dividing every feature by 255 (the maximum grayscale value) to bring all values into the range [0,1]."
      ],
      "metadata": {
        "id": "bC9KeeFmSwgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_value = np.max(X_train)\n",
        "max_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Hev_17S1So",
        "outputId": "292e0821-8e2f-4316-ac5c-f0720e7c0827"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255.0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train /= 255.0\n",
        "X_valid /= 255.0\n",
        "X_test /= 255.0\n"
      ],
      "metadata": {
        "id": "LZzNRVz4S-DW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Illustrating the normalised dataset\n",
        "\n",
        "#for i in range(len(X_valid)):\n",
        "#  print(X_valid[i])"
      ],
      "metadata": {
        "id": "xc2Qyg9mTfCn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, the data is ready to be used in the k-means algorithm.**"
      ],
      "metadata": {
        "id": "86mMiVo9TT1s"
      }
    }
  ]
}